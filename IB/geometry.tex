\documentclass[a4paper]{article}

\def\npart{IB}

\def\ntitle{Geometry}
\def\nlecturer{A.\ G.\ Kovalev}

\def\nterm{Lent}
\def\nyear{2018}

\input{header}

\theoremstyle{definition}
\newtheorem*{fact}{Fact}

\DeclareMathOperator{\Isom}{Isom}
\DeclareMathOperator{\mesh}{mesh}
\newcommand*{\inner}{\innerproduct}

\begin{document}

\input{titlepage}

\tableofcontents

\section{Eucldiean Geometry}

\subsection{Isometries}

Let \((\cdot, \cdot)\) be the standard inner product, a.k.a.\ dot product on the Euclidean space \(\R^n\) where for \(x, y \in \R^n\),
\[
  (x, y) = x \cdot y = \sum_{i = 1}^{n}x_iy_i.
\]
This induces the Euclidean norm
\[
  \norm x = \sqrt{(x, x)}.
\]
Also define the Euclidean distance function
\[
  d(x, y) = \norm{x - y}
\]
which makes \(\R^n\) a metric space.

\begin{definition}[Isometry]\index{isometry}
  A map \(f: \R^n \to \R^n\) is an \emph{isometry} of \(\R^n\) if
  \[
    \forall P, Q \in \R^n,\, d(f(P), f(Q)) = d(P, Q).
  \]
\end{definition}

Recall that an \(n \times n\) matrix \(A\) is \emph{orthogonal} if
\[
  A^TA = AA^T = I.
\]
For any square matrix \(A\) we have
\[
  (Ax, Ay) = (Ax)^T(Ay) = x^TA^TAy = (x, A^TAy)
\]
so we find that \(A\) is orthogonal if and only if \((Ax, Ay) = (x, y)\) for all \(x, y \in \R^n\).

Another point of view:
\[
  (x, y) = \frac{1}{2}(\norm{x + y}^2 -  \norm x^2 - \norm y^2)
\]
so \(A\) is orthogonal if and only if \(\norm{Ax} = \norm x\) for all \(x \in \R^n\).

An example of isometry: let \(f(x) = Ax + b\) where \(b \in \R^n\), then
\[
  d(f(x), f(y)) = \norm{A(x - y)}.
\]
So \(f\) is an isometry if and only if \(A\) is orthogonal.

Surprisingly, it turns out all isometries have this form:

\begin{theorem}
  Every isometry \(f: \R^n \to \R^n\) is of the form \(f(x) = Ax + b\) for some orthogonal matrix \(A\) and some vector \(b \in \R^n\).
\end{theorem}

\begin{proof}
  Let \(e_1, \dots, e_n \in \R^n\) be the standard basis of \(\R^n\). Let \(b = f(0)\), \(a_i = f(e_i) - b\) for \(i = 1, \dots, n\). We want to show that \(a_i\)'s form an orthonormal basis. Firstly
  \[
    \norm{a_i} = \norm{f(e_i) - f(0)} = d(f(e_i), f(0)) = d(e_i, 0) = \norm{e_i} = 1
  \]
  so they have unit length. For \(i \neq j\),
  \begin{align*}
    (a_i, a_j) &= -\frac{1}{2}(\norm{a_i - a_j}^2 - \norm{a_i}^2 - \norm{a_j}^2) \\
               &= -\frac{1}{2}(\norm{f(e_i) - f(e_j)}^2 - 2) \\
               &= -\frac{1}{2}(\norm{e_i - e_j}^2 - 2) \\
               &= 0
  \end{align*}
  Thus \(a_i\)'s form an orthonormal basis of \(\R^n\) and it follows that the matrix \(A\) with columns \(a_i, \dots, a_n\) is orthogonal.

  Let \(g(x) = Ax + b\) which is an isometry. We have \(g(x) = f(x)\) for \(x = 0, e_1, \dots, e_n\). In addition,
  \[
    g^{-1}(x) = A^{-1}(x - b) = A^T(x - b)
  \]
  is an isometry so the composition \(h = g^{-1} \compose f\) is an isometry fixing \(0, e_1, \dots, e_n\). It then suffices to show \(h = \id\). Consider \(x = \sum_{i = 1}^n x_ie_i \in \R^n\). Let \(y = h(x) = \sum_{i = 1}^n y_ie_i\). Then
\begin{align*}
  d(x, e_i)^2 &= \norm x^2 + 1 - 2x_i \\
  d(x, 0)^2 &= \norm x^2 \\
  d(y, e_i)^2 &= \norm y^2 + 1 - 2y_i \\
  d(y, 0)^2 &= \norm y^2
\end{align*}
Since \(h\) is an isometry, \(h(0) = 0\), \(h(e_i) = e_i\) and \(h(x) = y\), we have \(\norm x = \norm y\) so \(x_i = y_i\) for all \(i\). Thus \(h(x) = x\) for all \(x \in \R^n\).
\end{proof}

\begin{remark}
  \[
    \Isom(\R^n) = \{\text{all isometries of } \R^n\}
  \]
  is a group by composition. This is also known as the group of rigid motions of \(\R^n\).
\end{remark}

\begin{eg}[Reflections in an affine hyperplane \(H \subset \R^n\)]
  Let
  \[
    H = \{x \in \R^n: u \cdot x = c\}
  \]
  where \(\norm u = 1\) and \(c \in \R\). Observe that \(u\) is perpendicular to \(H\) and so is a normal vector. The reflection in \(H\) is defined to be
  \[
    R_H: x \mapsto x - 2(x \cdot u - c)u.
  \]
  It is an exercise in example sheet to show that this is an isometry. Observe that if \(x \in H\) then \(R_H(x) = x\). If \(a \in H, t \in \R\) then
  \[
    R_H(a + tu) = (a + tu) - 2tu = a - tu.
  \]
  Thus \(R_H\) fixes exactly the points in \(H\).

  Conversely, suppose \(S \in \Isom(\R^n)\) and \(S\) fixes every point in \(H\). Let \(a \in H\) and defind translation by \(a\) as
  \[
    T_a(x) = x + a
  \]
  which is clearly an isometry. Conjugate \(S\) by \(T_a\), we get
  \[
    R = T_{-a}ST_a \in \Isom(\R^n)
  \]
  and \(R\) fixes \(H' = T_{-a}(H)\). We choose to work with \(H'\) since \(0 \in H'\), making it a subspace of \(\R^n\). Explicitly, if \(H = \{x: x\cdot u = c\}\) then \(H' = \{x: x \cdot u = 0\}\). Then for all \(x \in H'\),
  \[
    (Ru, x) = (Ru, Rx) = (u, x) = 0.
  \]
  Thus \(Ru\) is orthogonal to \(H'\), i.e.\ lies in the orthogonal complement of \(H'\) in \(\R^n\). Thus \(Ru = \lambda u\) for some \(\lambda \in R\) such that \(\lambda^2 = 1\). So \(\lambda = \pm 1\).

  Since \(R\) fixes \(0 \in \R^n\), \(R\) is linear by the previous theorem and either \(R = \id\) or \(R\) is given by the matrix
  \[
    \begin{pmatrix}
      -1 & & \\
      & 1 & \\
      & & \ddots \\
      & & & 1
    \end{pmatrix}
  \]
  i.e.\ \(R_{H'}\). If \(R = \id\) then \(S = \id\). If \(R = R_{H'}\) then \(S = T_aR_{H'}T_{-a}\). Check that
  \[
    S: x \mapsto x - a \mapsto (x - a) - 2(x \cdot u - a \cdot u) u \mapsto x - 2(x \cdot u - c)u
  \]
  is a reflection. Thus if \(S \in \Isom(\R^n)\) fixing \(H\) and \(S \neq \id \) then \(R\) is the reflection in \(H\).
\end{eg}

\begin{remark}
  One can show that every isometry of \(\R^n\) is a composition of at most \(n + 1\) reflections (see example sheet 1).
\end{remark}

From the previous theorem, the subgroup
\[
  \{f \in \Isom(\R^n): f(0) = 0\} = \{f(x) = Ax: AA^T = I\}
\]
is naturally isomorphic to \(O(n)\), the \emph{orthogonal group}\index{orthogonal group}.

As for every \(A \in O(n)\), \((\det A)^2 = 1\), we must have \(\det A = \pm 1\). We call \(\{A \in O(n): \det A = 1\}\) the \emph{special orthgonal group}\index{orthogonal group!special}, denoted \(SO(n)\).

\begin{eg}[\(O(2)\)]
  \[
    A =
    \begin{pmatrix}
      a & c \\
      b & d
    \end{pmatrix}
    \in O(2) \Leftrightarrow a^2 + c^2 = 1, b^2 + d^2 = 1, ab + cd = 0
  \]
  Set \(a = \cos \theta, c = \sin \theta\) and \(b = - \sin \varphi, d = \cos \varphi\) for some \(0 \leq \theta, \varphi \leq 2\pi\). Then we deduce
  \[
    \tan \theta = \tan \varphi \in \R \cup \{\infty\}
  \]
  so
  \[
    \theta = \varphi \text{ or } \theta = \varphi \pm \pi.
  \]
  The first case corresponds to
  \[
    A =
    \begin{pmatrix}
      \cos \theta & -\sin \theta \\
      \sin \theta & \cos \theta
    \end{pmatrix}
  \]
  which is the rotation through \(\theta\) about \(0\). As \(\det A = 1\), \(A \in SO(2)\). The second case gives
  \[
    A =
    \begin{pmatrix}
      \cos \theta & \sin \theta \\
      \sin \theta & - \cos \theta
    \end{pmatrix}
  \]
  which we claim is a relfection: it fixes the line \(\ell\) which passes through the origin and forms an angle \(\theta/2\) with the positive \(x\)-axis. \(\det A = -1\) so \(A \notin SO(2)\).
\end{eg}

\begin{remark}[Orientation]\index{orientation}
  For a finite-dimensional vector space, its \emph{orientation} is an equivalence class of bases --- let \(v_1, \dots, v_n\) and \(v_1', \dots, v_n'\) be two bases, and \(A = (A_{ij})\) be the respective change-of-basis from \(\{v_i\}\) to \(\{v_i'\}\). These bases are equivalent, i.e.\ give the \emph{same orientation}, if \(\det A > 0\).
\end{remark}

\begin{definition}
  An isometry \(f(x) = Ax + b\) is said to be \emph{orientation-preserving} if \(\det A = 1\), and \emph{orientation-reversing} if \(\det A = -1\).
\end{definition}

\begin{eg}{\(O(3)\)}
Let's study \(O(3)\) in detail. Consider first the case \(\det A = 1\), then
\[
  \det(A - I) = \det(A^T -I) = \det(A(A^T - I)) = \det(I - A).
\]
Since \(A\) is a \(3 \times 3\) matrix, we must have \(\det (A - I) = 0\) so \(+1\) is an eigenvalue. Thus there exists \(v_1 \in \R^3, \norm{v_1} = 1\) such that \(Av_1 = v_1\). Set \(W = \generation{v_1}^\perp\), a plane. Then for \(w \in W\),
\[
  (Aw, v_1) = (Aw, Av_1) = (w, v_1) = 0
\]
so \(A\) is \(W\)-stable. Thus \(A|_W\) is a \emph{rotation} of the \(2\) dimensional space \(W\). Choose \(v_2, v_3\) to be an orthonormal basis of \(W\), then \(A\) has matrix representation with respect to \(v_1, v_2, v_3\)
\[
  \begin{pmatrix}
    1 & 0 & 0 \\
    0 & \cos \theta & -\sin \theta \\
    0 & \sin \theta & \cos \theta
  \end{pmatrix}
\]

Now suppose \(\det A = -1\). Then \(-A\) in some basis is of the above matrix form. Thus \(A\) is of the form
\[
  \begin{pmatrix}
    -1 & 0 & 0 \\
    0 & \cos \varphi & -\sin \varphi \\
    0 & \sin \varphi & \cos \varphi
  \end{pmatrix}
\]
where \(\varphi = \theta + \pi\). This is a \emph{rotated reflection} (in particular a pure reflection when \(\varphi = 0\)).
\end{eg}

\subsection{Curves in \texorpdfstring{\(\R^n\)}{‚Ñù\^{}n}}

\begin{definition}[Curve]\index{curve}
  A \emph{curve} \(T\) in \(\R^n\) is a continuous map \(\Gamma: [a, b] \to \R^n\).
\end{definition}

A \emph{dissection} \(\mathcal D\) is a sequence
\[
  a = t_0 < t_1 < \dots, t_N = b \in [a, b].
\]
Set \(P_i = T(t_i)\) and let
\[
  s_{\mathcal D} = \sum_i \norm{P_iP_{i + 1}}.
\]

\begin{definition}[Length]\index{length}
  The \emph{length} of a curve \(\Gamma\) is
  \[
    \ell = \sup_{\mathcal D} s_{\mathcal D}
  \]
  if this supremum exists (i.e.\ finite).
\end{definition}

If \(\mathcal D'\) is a refinement of \(\mathcal D\) (has extra points added), then \(s_{\mathcal D} \leq s_{\mathcal D'}\) by triangle inequality. Let
\[
  \mesh \mathcal D = \max_i(t_i - t_{i - 1}).
\]
Then if \(\ell\) exists, we have
\[
  \ell = \lim_{\mesh \mathcal D \to 0} s_{\mathcal D}.
\]

\begin{note}
  In fact we have
  \[
    \ell = \min\{\tilde \ell: \tilde \ell \geq s_{\mathcal D} \text{ for all } \mathcal D\}.
  \]
\end{note}

\begin{proposition}
  If \(\Gamma\)  is continuously differentiable, then
  \[
    \ell(\Gamma) = \int_a^b \norm{\Gamma'(t)} dt.
  \]
\end{proposition}

\begin{proof}
  Assume \(n = 3\) to avoid excessive notation. Let
  \[
    \Gamma(t) = (f_1(t), f_2(t), f_3(t)).
  \]
  If \(s \neq t \in [a, b]\), applying Mean Value Theorem to each \(f_i\) gives us
  \[
    \frac{f_i(t) - f_i(s)}{t - s} = f'_i(\xi_i)
  \]
  for some \(s < \xi_i < t\). \(f_i'\) are uniformly continuous on \([a, b]\) so for all \(\varepsilon > 0\) there exists \(\delta > 0\) such that
  \[
    |t - s| < \delta \implies |f_i'(\xi_i) - f_i'(\xi)| < \frac{\varepsilon}{3} \, \forall \xi \in (s, t).
  \]
  So for all \(\xi \in (s, t)\),
  \begin{align*}
    \norm*{\frac{\Gamma(s) - \Gamma(t)}{s - t} - \Gamma'(\xi)} &= \norm{(f_1'(\xi_1), f_2'(\xi_2), f_3'(\xi_3)) - (f_1'(\xi), f_2'(\xi), f_3'(\xi))} \\
                                                               &< \frac{\varepsilon}{3} + \frac{\varepsilon}{3} +\frac{\varepsilon}{3} \\
                                                               &= \varepsilon
  \end{align*}
  i.e.
  \[
    \norm{(\Gamma(t) - \Gamma(s)) - (t - s)\Gamma'(\xi)} < \varepsilon(t - s)
  \]
  for all \(\xi \in (s, t)\). Specialise to \(t = t_i, s= t_{i - 1}, \xi = \frac{t_i + t_{i - 1}}{2}\) and sum over \(i\), we get
  \[
    \sum_i \norm*{(\Gamma(t_i) - \Gamma(t_{i - 1})) - (t_i - t_{i - 1}) \Gamma'\left(\frac{t_i + t_{i - 1}}{2}\right)} < \sum_i \varepsilon(t_i - t_{i - 1}) = \varepsilon(b - a).
  \]
  Now if \(\mesh \mathcal D < \delta\) then the reverse triangle inequality gives
  \[
    \left|s_{\mathcal D}  - \sum_i (t_i - t_{i - 1}) \norm*{\Gamma'\left(\frac{t_i + t_{i - 1}}{2}\right)}\right| < \varepsilon (b - a).
  \]
  Finally, as \(\norm{\Gamma'(t)}\) is a continuous function of \(t\), it is integrable so the summation converges to \(\int_a^b \norm{\Gamma'(t)} dt\) as \(\mesh \mathcal D \to 0\). Thus
  \[
    \ell(\Gamma) = \lim_{\mesh \mathcal D \to 0} s_{\mathcal D} = \int_a^b \norm{\Gamma'(t)} dt
  \]
  as required.
\end{proof}

\section{Spherical Geometry}

\begin{notation}
  Let \(S^2 \subseteq \R^3\) be the unit sphere with centre \(0\). A \emph{great circle}\index{great circle}, sometimes also called a \emph{(spherical) line}, is \(S^2 \cap \text{a plane through } 0\). For all non-antipodal pair of points \(P, Q \in S^2\), there is a unique line in \(S^2\) passing through \(P\) and \(Q\). It is given by the intersection of \(S^2\) and the plane through \(P, Q, 0\).
\end{notation}

\begin{definition}[Distance on sphere]
  For \(P, Q \in S^2\), the \emph{distance} \(d(P, Q)\) is the length of the shorter of two line segments \(PQ\) along the great circle through \(P, Q\). \(d(P, Q) = \pi\) if \(P\) and \(Q\) are antipodal.
\end{definition}

\begin{note}
  \begin{align*}
    d(P, Q) &= \text{angle between } \V P = OP \text{ and } \V Q = OQ \\
            &= \cos^{-1} (\V P \cdot \V Q)
  \end{align*}
\end{note}

\begin{definition}[Spherical triangle]\index{spherical triangle}
  A \emph{sperical triangle}, \(ABC\) say, is defined like a Euclidean triangle but with \(AB, AC, BC\) line segments on \(S^2\) with lengths \(< \pi\).
\end{definition}

\begin{notation}
  \(\V A = OA\) etc.
\end{notation}

Set
\begin{align*}
  n_1 &= \frac{\V C \times \V B}{\sin a} \\
  n_2 &= \frac{\V A \times \V C}{\sin b} \\
  n_3 &= \frac{\V B \times \V A}{\sin c}
\end{align*}
which are the unit normals to the plane \(OBC\), \(OAC\), \(OAB\) pointing out of the solid \(OABC\). \(\alpha, \beta, \gamma\) are the angles between the planes defining sides of \(ABC\).

\begin{note}
  The angle between \(n_2\) and \(n_3\) is \(\pi + \alpha\) so \(n_2 \cdot n_3 = -\cos \alpha\). Similarly for the other two terms.
\end{note}

\begin{theorem}[Spehrical cosine rule]
  \[
    \sin a \sin b \cos \gamma = \cos c - \cos a \cos b.
  \]
\end{theorem}

\begin{proof}
  We use
  \[
    (\V C \times \V B) \cdot (\V A \times \V C) = (\V A \cdot \V C)(\V B \cdot \V C) - (\V C \cdot \V C)(\V B \cdot \V A)
  \]
  which we derived in IA Vector Calculus. Note that \(|\V C| = 1\) and
  \begin{align*}
    -\cos \gamma &= n_1 \cdot n_2 \\
                 &= \frac{\V C \times \V B}{\sin a} \cdot \frac{\V A \times \V C}{\sin b} \\
                 &= \frac{(\V A \cdot \V C)(\V B \cdot \V C) - (\V B \cdot \V A)}{\sin a \sin b} \\
                 &= \frac{\cos b \cos a - \cos c}{\sin a \sin b}
  \end{align*}
\end{proof}

\begin{corollary}[Spherical Pythagoras Theorem]
  If \(\gamma = \frac{\pi}{2}\) then
  \[
    \cos c = \cos a \cos b.
  \]
\end{corollary}

\begin{theorem}[Spherical sine rule]
  \[
    \frac{\sin a}{\sin \alpha} = \frac{\sin b}{\sin \beta} = \frac{\sin c}{\sin \gamma}.
  \]
\end{theorem}

\begin{proof}
  Use the identity
  \[
    (\V A \times \V C) \times (\V C \times \V B) = (\V C \cdot (\V B \times \V A)) \V C.
  \]

  Note that LHS equals to
  \[
    -(n_1 \times n_2) \sin a \sin b
  \]
  and note that the angle between \(n_1\) and \(n_2\) is \(\pi + \gamma\).

  Consider the plane through \(0\) that is orthogonal to \(\V C\). We find
  \[
    n_1 \times n_2 = \V C \sin \gamma.
  \]
  Thus the coefficient of \(\V C\) is
  \[
    \V C \cdot (\V B \times \V A) = -\sin a \sin b \sin \gamma.
  \]
  By the symmetry cof triple product, it also equals to
  \[
    \V A \cdot (\V C \times \V B) = -\sin b \sin c \sin \alpha.
  \]
  Equating them we get
  \[
    \frac{\sin c}{\sin \gamma} = \frac{\sin a}{\sin \alpha}.
  \]
\end{proof}

\begin{remark}
  Observe that for small \(a, b, c\), piece of \(S^2\) is approximated better and better by piece of \(\R^2\). Formally,
  \begin{align*}
    \sin a &= a + O(a^3) \\
    \cos a &= 1 - \frac{a^2}{2} + O(a^4)
  \end{align*}
  Thus we can obtain Euclidean version of cosine and sine rule by setting \(a, b, c\) small:
  \begin{align*}
    ab\cos \gamma &= (1 - \frac{c^2}{2}) - (1 - \frac{a^2}{2})(1 - \frac{b^2}{2}) + O(\norm{(a, b, c)}^3) \\
    c^2 + 2ab \cos \gamma &= a^2 + b^2 + O(\norm{(a, b, c)}^3)
  \end{align*}
\end{remark}

Now we discuss the metric property of spherical geometry. If \(\gamma = \pi\) then \(\V C\) lines in the line segment \(AB\) so \(c = a + b\). Otherwise, from Spherical cosine rule,
\[
  \cos c > \cos a \cos b - \sin a \sin b = \cos(a + b).
\]
As \(\cos\) is decresasing on \([0, \pi]\) and \(0 < c < \pi\), \(0 < a + b < 2\pi\), we have
\[
  c < a + b.
\]
This gives us

\begin{corollary}[Spherical triangle inequality]
  \[
    d(P, Q) + d(Q, R) \geq d(P, R)
  \]
  with equality if \(Q\) is in line segment \(PR\) of shorter length.
\end{corollary}
Thus we have shown that \((S^2, d)\) is a metric space.

\begin{proposition}
  Given a curve \(\Gamma\) on \(S^2 \subseteq \R^3\) from \(P\) to \(Q\) with length \(\ell\), we have
  \[
    \ell \geq d(P, Q).
  \]
  Moreover, if \(\ell = d(P, Q)\), then the image of \(\Gamma\)is a spherical line segment.
\end{proposition}

\begin{proof}
  Let \(\Gamma: [0, 1] \to S^2\) with length \(\ell\).For any dissection \(\mathcal D\) of \([0, 1]\) with
  \[
    0 = t_1 < t_1 < \dots < t_N = 1
  \]
  and \(P_i = \Gamma(t_i)\). Define two sums
  \[
    \tilde s_{\mathcal D} = \sum_{i = 1}^N d(P_{i -1}, P_i) > s_{\mathcal D} = \sum_{i = 1}^N |P_{i - 1}P|
  \]
  because the arc is longer than a sector, i.e.\ \(2\theta < 2 \sin \theta\).

  Suppose \(\ell < d(P, Q)\), we can deduce that there exists \(\varepsilon > 0\) such that \((1 + \varepsilon)\ell < d(P, Q)\). As \(\lim_{\theta \to 0} \frac{\sin \theta}{\theta} = 1\),
  \[
    2\theta \leq (1 + \varepsilon) 2\sin \theta
  \]
  for each small \(\theta > 0\).

  \(\Gamma\) is uniformly continuous on \([0, 1]\) so we can choose a refined \(\mathcal D\) such that
  \[
    d(P_{i - 1}, P_i) \leq (1 + \varepsilon)|P_{i - 1}P_i|
  \]
  for all \(i\). Therefore
  \[
    \tilde s_{\mathcal D} \leq (1 + \varepsilon)s_D \leq (1 + \varepsilon)\sup_{\mathcal D} s_{\mathcal D} = (1 + \varepsilon) \ell < d(P, Q).
  \]
  But \(\tilde s_{\mathcal D} \geq d(P, Q)\) by repeated use of spherical triangle inequality. Absurd.

  Suppose instead \(\ell = d(P, Q)\) for some \(\Gamma: [0, 1] \to S^2\). Then for all \(t \in [0, 1]\),
  \begin{align*}
    d(P, Q) &= \ell \\
            &= \operatorname{length} \Gamma|_{[0, t]} + \operatorname{length} \Gamma|_{[t, 1]} \\
            &\geq d(P, \Gamma(t)) + d(\Gamma(t), Q) \\
            &\geq d(P, Q) 
  \end{align*}
  Thus we have equality throughout. By spherical triangle equality the image of \(\Gamma\) is the shorter line segment from \(P\) to \(Q\).
\end{proof}

\begin{remark}
  If \(\Gamma\) is the shortest path between \(P\) and \(Q\) then \(\Gamma\) is a spherical line segment. Furthermore, from argument of the above proposition
  \[
    \operatorname{length} \Gamma|_{[0, t]} = d(P, \Gamma(t))
  \]
  so the parameterisation of \(\Gamma\) is \emph{monotonic}. In further courses in geometry such as IID Differential Geometry, such \(\Gamma\)'s are sometimes called \emph{minimising geodesics}. See example sheet 1 for a similar but easier discussion of geodesics in Euclidean space.
\end{remark}

\subsection{Area of spherical triangles}

\begin{proposition}[Gauss-Bonnet for \(S^2\)]
  If \(\Delta\) is a spherical triangle with angles \(\alpha, \beta, \gamma\), then
  \[
    \operatorname{area} \Delta = (\alpha + \beta + \gamma) - \pi.
  \]
\end{proposition}

\begin{proof}
  We assume the area of \(S^2\) is \(4\pi\) and the additivity of areas.

  A \emph{double line} with angle \(0 < \alpha < \pi\) is two antipodal regions on \(S^2\) cut out by planes through antipodal \(A, A' \in S^2\) where \(\alpha\) is the angle between planes. The area of such double line is \(4\alpha\). Then a triangle \(\Delta = ABC\) is the intersection of 3 single lines. The \(\Delta\) and its antipodal \(\Delta'\) lie in each of the three double lines with angles \(\alpha, \beta, \gamma\). Any other point \(P \in S^2 \setminus (\Delta \cup \Delta')\) is in only one double line. Thus
  \[
    4(\alpha + \gamma + \gamma) = 4\pi + 2 \cdot (\operatorname{area}\Delta + \operatorname{area}\Delta').
  \]
  The result thus follows.
\end{proof}

\begin{remark}\leavevmode
  \begin{enumerate}
  \item spherical triangles have \(\alpha + \beta + \gamma > \pi\). As the area of a triangle tends to \(0\), \(\alpha + \beta + \gamma \to \pi\). Thus Euclidean space is an approximation of sphere..
  \item If \(M\) is a convex \(n\)-gon in \(S^2\) where \(n \geq 3\), i.e.\ for all \(P, Q \in M\), the shorter line segment \(PQ\) is in \(M\). Let the interior angles be \(\alpha_1, \dots, \alpha_n\). Then
    \[
      \operatorname M = \sum_{i = 1}^n \alpha_i - (n - 2)\pi
    \]
    by cutting \(M\) into triangles.
  \end{enumerate}
\end{remark}

\subsection{M√∂bius geometry}

Consider \(\C_\infty = \C \cup \{\infty\}\).

\begin{definition}[Stereographic projection]\index{stereographic projection}
  The \emph{stereographic projection} is a map \(\pi: S^2 \to C_\infty\) where the north pole is mapped to \(\infty\) and other point is mapped to the intersection of the line through \(P\) and the north pole and the complex plane.
\end{definition}

We will use \(\zeta = x + iy\) to denote a point in \(\C_\infty\). From similar triangles we get
\[
  \pi(x, y, z) = \frac{x + iz}{1 - z}.
\]

\begin{lemma}
  If \(\pi': S^2 \to \C_\infty\) is the stereographic projection from the soth pole \((0, 0, -1)\) then
  \[
    \pi'(P) = \frac{1}{\conj{\pi(P)}}
  \]
  for all \(P \in S^2\).
\end{lemma}

\begin{proof}
  Easy once we write down the coordinates. Suppose \(P = (x, y, z)\). Then
  \begin{align*}
    \pi(P) &= \frac{x + iy}{1-z} \\
    \pi'(P) &= \frac{x + iy}{1 + z}
  \end{align*}
  and so
  \[
    \conj{\pi(P)} \cdot \pi'(P) = \frac{x^2 + y^2}{1 - z^2} = 1
  \]
  as \(S^2 = \{x^2 + y^2 + z^2 = 1\}\).
\end{proof}

\begin{note}
  \(\pi' \compose \pi^{-1}: \C_\infty \to \C_\infty\) takes \(\zeta \to \frac{1}{\conj \zeta}\), the \emph{inversion} in the circle \(|\zeta| = 1\).
\end{note}

Antipodal points

If \(P = (x, y, z) \in S^2\), then \(\pi(P) = \frac{x + iy}{1 - z} \in \C_\infty\), \(\pi(-P) = \frac{-x - iy}{1 + z}\) so
\[
  \pi(P) \cdot \conj{\pi(-P)} = -\frac{x^2 + y^2}{1 - z^2} = -1
\]
so \(\pi(-P) = -\frac{1}{\conj \zeta}\) where \(\zeta = \frac{x + iy}{1 - z}\).

\subsubsection{M√∂bius Transformations}

M√∂bius transformations act on \(\C_\infty\) and form a group \(G\). Given any matrix with complex entries \(A = \begin{psmallmatrix} a & b \\ c & d \end{psmallmatrix}\), define
\begin{align*}
  \C_\infty &\to \C_\infty \\
  \zeta &\mapsto \frac{a\zeta + b}{c\zeta + d}
\end{align*}
For all \(\lambda \in \C^* = \C \setminus \{0\}\), \(\lambda A\) defines the same M√∂bius transformation. The converse is also true: if \(A_1, A_2\) define the same M√∂bius transformation then there exists \(\lambda\) such that \(A_1 = \lambda A_2\). Therefore from group theory we know
\[
  G \cong \PGL(2, \C) = \GL(2, \C)/\C^*.
\]
Thus it suffices to assume \(\det A = 1\). But this does not eliminate all ambiguities --- if \(1 = \det(\lambda \tilde A) = \lambda^2 \det \tilde A = \lambda^2\) then \(\lambda = \pm 1\). Thus
\[
  G \cong \PSL(2, \C) = \SL(2, \C)/\{\pm 1\}.
\]

On \(S^2\) we have rotations \(\SO(3)\) acting as isometries (see example sheet). Which M√∂bius transformations do they correspond to?

\begin{theorem}
  Via the stereographic projection, every rotation of \(S^2\) induces a M√∂bius transformation defiend by a matrix in \(\SU(2) \leq \SL(2, \C)\).
\end{theorem}

\begin{proof}
  Denote by \(r(z, \theta)\) the rotation about the \(z\)-axis through \(\theta\). Then it corresponds to the M√∂bius map \(\zeta \mapsto e^{i\theta} \theta\) with a matrix
  \[
    \begin{pmatrix}
      e^{i\theta/2} & 0 \\
      0 & e^{-i\theta/2}
    \end{pmatrix}
    \in \SU(2).
  \]

  Next, the rotation \(r(y, \frac{\pi}{2})\) has matrix
  \[
    \begin{pmatrix}
      0 & 0 & 1 \\
      0 & 1 & 0 \\
      -1 & 0 & 0
    \end{pmatrix}
  \]
  correspond to \(\zeta = \frac{x + iy}{1 - z} \mapsto \zeta' = \frac{z + iy}{1 + x}\) since by drawing a diagram we know
  \begin{align*}
    -1 &\mapsto \infty \\
    1 &\mapsto 0 \\
    i &\mapsto i
  \end{align*}
  The corresponding unique M√∂bius map is then \(\zeta' = \frac{\zeta - 1}{\zeta + 1}\). We check that
  \begin{align*}
    \frac{\zeta - 1}{\zeta + 1}
    &= \frac{x + iy - 1 + z}{x + iy +1 - z} \\
    &= \frac{x - 1 + z + iy}{x + 1 - (z - iy)} \\
    &= \frac{(z + iy)(x - 1 + z + iy)}{(x + 1)(z + iy) + (x^2 - 1)} \\
    &= \frac{(z + iy)(x - 1 + z + iy)}{(x + 1)(z + iy + x -1)} \\
    &= \zeta'
  \end{align*}
  does give the rotation we want.

  We claim that \(\SO(3)\) is generated by \(r(y, \frac{\pi}{2})\) and \(r(z, \theta)\). Observe that
  \[
    r(x, \varphi) = r(y, \frac{\pi}{2}) r(z, \varphi) r(y, -\frac{\pi}{2})
  \]
  which is a conjugation. To check this, note that the \((1, 0, 0)\) is an eigenvector and the map is orientation-preserving (and some more geometric arguments). Also for all \(x \in S^2 \subseteq \R^3\), there exists \(\varphi, \psi\) such that \(g =r(z, \psi) r(x, \varphi)\) which maps \(v\) to \((1, 0, 0)\): choose \(r(x, \varphi)\) rotating \(v\) to the \((x, y)\)-plane. Then \(r(v, \theta) = g^{-1} r(x, \theta) g\) and the claim follows.

  Thus via projection, any rotation of \(S^2\) corresponds to a finite product of M√∂bius transformations with matrices in \(\SU(2)\).
\end{proof}

The theorem gives a group homomorphism
\[
  \SO(3) \to \PSU(2) \cong \SU(2)/\{\pm I\}
\]
which is in fact surjective, so an isomrphism.

\begin{theorem}
  The group \(\SO(3)\) of rotations of \(S^2\) correponds precisely to the subgroup \(\PSU(2) \cong \SU(2)/\{\pm I\}\) of M√∂bius transformations acting on \(\C_\infty\).
\end{theorem}

\begin{proof}
  Let \(g \in \PSU(2) \leq G, g(z) = \frac{az - b}{\conj b z + \conj a}\). Suppose \(g(0) = 0\), so \(b = 0\), \(a \conj a = 1\) so let \(a = e^{i\theta/2}\) where \(\theta \in \R\). Then \(g\) corresponds to \(r(z, \theta)\). In general, \(g(0) = w \in C_\infty\). Let \(Q \in S^2\), \(\pi(Q) = w\). Choose \(A \in \SO(3)\) with \(A(Q) = (0, 0, -1)\). Let \(\alpha \in \PSU(2)\) be the correponding M√∂bius map in \(\PSU(2)\). Thus \(\alpha(w) = 0\) and \(\alpha \compose g(0) = 0\). So \(\alpha \compose g\) correponds to an element \(B\) in \(\PSU(2)\), and thus \(g\) corresponds to \(A^{-1}B\).
\end{proof}

\begin{remark}
  The map
  \[
    \SU(2)/\{\pm I\} \cong \SO(3)
  \]
  is a double cover.
\end{remark}

\section{Triangulations and the Euler number}

First introduce one more ``geometry'': the locally Euclidean torus.

\begin{definition}[Torus]\index{torus}
  The \emph{torus} \(T\) is the set \(\R^2/\Z^2\)of equivalence classes of \((x, y) \in \R^2\) with equivalence relation
  \[
    (x_1, y_1) \sim (x_2, y_2) \Leftrightarrow x_1 - x_2, y_1, y_2 \in \Z.
  \]
\end{definition}

Thus a point in \(T\) is a coset \((x, y) + \Z^2\) of the subgroup \(\Z^2\) of \((\R^2, +)\).

For a closed square \(Q \subseteq \R^2\) with side length \(1\), \(T\) is obtained by identifying the opposite sides.

Define the distance \(d\), for \(P_1, P_2 \in T\)
\[
  d(P_1, P_2) = \min \{|v_1 - v_2|: v_1, v_2 \in \R^2, v_i + \Z^2 = P_i\}.
\]
It is easy to check \((T, d)\) is a metric space.

Let \(Q^0\) be the interior of \(Q\). The natural map
\begin{align*}
  f: Q^0 &\to T \\
  v &\mapsto v + \Z^2
\end{align*}
is a bijection onto an open set \(U = f(Q^0) \subseteq T\). Moreover \(f: Q^0 \to U\) is a homeomorphism. Let \(P \in Q\). \(f\) restricted to small open disc about \(P\) is an \emph{isometry} onto the image. Such \(d\) (on \(T\)) is said to correspond to a \emph{locally Euclidean metric} on \(T\).

\(T\) maybe embedded in \(\R^3\) but the distance function we get by considering curves on \(T \subseteq \R^3\) is \emph{not} the same as the locally Euclidean distance.

\begin{definition}[Topological triangle]\index{topological triangle}
  A \emph{topological triangle} on \(X = S^2\) or \(T\) (or in general, any metric space \(X\)) is the image \(R \subseteq X\) of a closed Euclidean triangle \(\triangle \subseteq \R^2\) under a homeomorphism \(\triangle \to R\).
\end{definition}

For example, any spherical triangle is a topological triangle, by using radial projection from \(0\) to an affine plane in \(\R^2\).

\begin{definition}[Topological triangulation]\index{topological triangulation}
  A \emph{(topological) triangulation} \(\tau\) of \(X\) is a finite collection of topologtical triangles which cover \(X\) and satisfy
  \begin{enumerate}
  \item every two topological triangles of \(\tau\) are either disjoint, or meet in exactly one edge, or meet in exactly one vertex.
  \item each edge belongs to exactly two triangles.
  \end{enumerate}
\end{definition}

\begin{definition}[Euler number]\index{Euler number}
  The \emph{Euler number} \(e = e(X, \tau)\) is
  \[
    e = F - E + V
  \]
  where \(F = \# \text{faces in } \tau\), \(E = \#\text{edges in } \tau\) and \(V = \# \text{vertices in } \tau\).
\end{definition}

\begin{fact}[From algebraic topology]
  \(e\) is independent of the choice of \(\tau\), i.e.\ \(e = e(X)\).
\end{fact}

\begin{eg}
  (See pictures.)

  In both examples we use \emph{geodesic triangles}, i.e.\ used spherical triangles on \(S^2\) and Euclidean triangles on \(Q^0\).
\end{eg}

\begin{proposition}
  Each geodesic triangulation of \(S^2\), repsectively \(T\), has \(e = 2\), respectively \(0\).
\end{proposition}

\begin{remark}
  The results also hold without the geodesic assumption but we will not prove it in this course.
\end{remark}

\begin{proof}
  Denote the faces \(\triangle_1, \dots, \triangle_F\) and \(\tau_i = \alpha_i + \beta_i + \gamma_i\), \(i = 1, \dots, F\) the interior angles. Then \(\sum_{i = 1}^F \tau_i = 2\pi V\). Also \(3F = 2E\) so \(F = 2E - 2F\).
  \begin{itemize}
  \item \(S^2\): Gauss-Bonnet says \(\operatorname{area} \triangle_i = \tau_i - \pi\) so
    \begin{align*}
      4\pi
      &= \sum_{i = 1}^F \operatorname{area} \triangle_i \\
      &= \sum_{i = 1}^F (\tau_i - \pi) \\
      &= 2\pi V - \pi F \\
      &= 2\pi V - 2\pi E + 2\pi F \\
      &= 2\pi V
    \end{align*}
    so \(e = 2\).
  \item \(T\): \(\tau_i = \pi\) for all \(i\) so
    \begin{align*}
      2\pi V &= \sum_{i = 1}^F \tau_i = \pi F \\
      2V &= F = 2 E - 2F
    \end{align*}
    thus \(e = 0\).
  \end{itemize}
\end{proof}

\begin{remark}
  We can use topological polygonal decomposition of \(X\) and the proposition above still holds. The Euler's formula for \(S^2\) is
  \[
    V - E + F = 2.
  \]
\end{remark}

\section{Hyperbolic geometry}

There are three ``classical'' types of ``geometries'' and we have seen two of them: Euclidean and spherical. The third type is hyperbolic geometry. We shall require the concept of \emph{Riemannian metric} on an open \(U \subseteq \R^2\).


\subsection{Revision of differentiability}

It would be convenient to recall from IA Analysis I and IB Analysis I facts about the derivatives and make precise sense of the \emph{differentials}.

Let \(U \subseteq \R^n\) be an open set, \(f = (f_1, \dots, f_m): U \to \R^m\). \(f\) is smooth, i.e.\ \(C^\infty\), if each \(f_i\) has continuous partial derivatives of every order. In particular, \(C^\infty\) implies the existence of continuous derivatives of 1st order so it is differentiable.

The derivatives of \(f\) at \(a \in U\) is a linear map \(df_a: \R^n \to \R^m\) such that
\[
  \lim_{h \to 0} \frac{\norm{f(a + h) - f(a) - df_a \cdot h}}{\norm h} = 0.
\]
If \(m = 1\), \(df_a\) is determined by
\[
  \left( \frac{\p f}{\p x_1}(a), \dots, \frac{\p f}{\p x_n}(a) \right)
\]
via
\[
  df_a: (h_1, \dots, h_n) \mapsto \sum_{i = 1}^n \frac{\p f}{\p x_i}(a) h_ii.
\]

For general \(m\), we may use the \emph{Jacobian matrix}
\[
  J(f)_a = \left( \frac{\p f_i}{\p x_j}(a) \right)
\]
and use matrix multiplication
\[
  h \mapsto J(f)_ah.
\]

\begin{eg}
  Consider a holomorphic, i.e.\ analytic function function of complex variable \(f: U \to \C\) where \(U \subseteq \C\) is open, with derivative \(f'(z)\) such that
  \[
    \lim_{w \to 0} \frac{|f(z + w) - f(z) - f'(z)w|}{|w|} = 0.
  \]
  Suppose \(f'(z) = a + ib\) and \(w = h_1 + ih_2\), then
  \[
    f'(z)w = (ah_1 - bh_2) + i(ah_2 + bh_1)
  \]
  Now identify \(\C \cong \R^2\), \(f: U \to \R^2\) has derivative \(df_z: \R^2 \to \R^2\) given by
  \[
    \begin{pmatrix}
      a & -b \\
      b & a
    \end{pmatrix}
  \]
\end{eg}

Chain rule: let \(U \subseteq \R^n, V \subseteq \R^p\) both open, \(f: U \to \R^m, g: V \to U\) both smooth. THen \(f \compose: V \to \R^m\) has for all \(p \in V\),
\[
  d(f \compose g)_p = (df)_{g(p)} \compose (dg)_p
\]
or in terms or Jacobians,
\[
  J(f \compose g)_p = J(f)_{g(p)} \cdot J(g)_p
\]
where \(\cdot\) denotes matrix multiplication.

\subsection{Riemannian metrics on open sets in \texorpdfstring{\(\R^2\)}{‚Ñù\^{}2}}

Use the coordinates \((u, v) \in \R^2\). Let \(V \subseteq \R^2\) be open.

\begin{definition}[Riemannian metric]\index{Riemannian metric}
  A \emph{Riemannian meric} is define by giving \(C^\infty\) functions \(E, F, G: V \to \R\) such that
  \[
    \begin{pmatrix}
      E(p) & F(p) \\
      F(p) & G(p)
    \end{pmatrix}
  \]
  is a positive-definite matrix for all \(p \in V\).
\end{definition}

Hence a Riemannian metric defines an inner product \(\inner{\cdot, \cdot}_p\) on \(\R^2\).

\begin{remark}
  There are two ways to view \(\R^2\): one way is the standard vector space \(\R^2\), which has a distinguished zero vector. The other is the affine space \(\A^2\) (space of points) with operation
  \[
    \text{point } + \text{ vector } = \text{ point}.
  \]
  So the inner product could be thought of an operation on the affine space, with \(p\) identified as the zero.
\end{remark}

Let \(e_1, e_2\) be the standard basis of \(\R^2\). Then given the inner product defined above,
\begin{align*}
  \inner{e_1, e_1}_p &= E(p) \\
  \inner{e_1, e_2}_p &= F(p) \\
  \inner{e_2, e_2}_p &= G(p)
\end{align*}

\begin{notation}
  Use \(E du^2 + 2F dudv + G dv^2\) to denote a family of inner products.

  For pedagogical purpose it might be helpful to explain the origin of the notation \(du, db\). Let \(u, v: V \to \R\) be the components of the coordinates, which are \(C^\infty\). Since they are linear maps, their derivatives are just themselves, i.e.\ for all \(p \in V\)
  \begin{align*}
    (du)_p: \R^2 &\to \R \\
    (h_1, h_2) &\mapsto h_1 \\
    (dv)_p: \R^2 &\to \R \\
    (h_1, h_2) &\mapsto h_2
  \end{align*}
  Since the derivatives do not depend on \(p\), we write \(du, dv\) for brevity, which are elements of the dual space \((\R^2)^*\). Furthermore, \(du, dv\) form the \emph{dual} basis to standard basis \(e_1, e_2\) of \(\R^2\). Then \(du^2, dudv, dv^2\) are symmetric bilinear forms on \(\R^2\), with
  \begin{align*}
    du^2(h, k) &= du(h) du(k) \\
    dudv(h, k) &= \frac{1}{2}(du(h)dv(k) + du(k)dv(k)) \\
    dv^2(h, k) &= \dots
  \end{align*}
  with matrices given by ...

  and so \(Edu^2 + 2Fdudv + Gdv^2\) is indeed the bilinear form \(\begin{psmallmatrix} E & F \\ F & G \end{psmallmatrix}\).
\end{notation}

\begin{definition}[Length]\index{length}
  The \emph{length with repsect to a Riemannian metric} of smooth curve \(\gamma = (\gamma_1, \gamma_2): [0, 1] \to V \subseteq \R^2\) is
  \[
    \int_0^1 \inner{\dot \gamma, \dot \gamma}_{\gamma(t)}dt = \int_0^1 (E \dot \gamma_1^2 + 2F \dot \gamma_1 \dot \gamma_2 + G \dot \gamma_2^2)^{1/2} dt.
  \]
\end{definition}

Note that this is compatible with the definition of length in Euclidean metric, with \(E = G = 1, F = 0\).

\begin{definition}
  The \emph{area with respect to a Riemannian metric} of a region \(W \subseteq V\) is defined as
  \[
    \int_W (EG - F^2)^{1/2} dudv
  \]
  whenever the integral exists.
\end{definition}

Note that \(EG - F^2 = \det \begin{psmallmatrix} E & F \\ F & G \end{psmallmatrix}\), the Gram determinant.

\begin{eg}
  Let \(V = \R^2\) with Riemannian metric
  \[
    \frac{4 (du^2 + dv^2)}{(1 + u^2 + v^2)^2}.
  \]
  Recall the stereographic projection
  \begin{align*}
    \pi: S^2 \setminus \{N\} &\to \R^2 \\
    (x, y, z) &\mapsto (u, v)
  \end{align*}
  For all \(P \neq N \in S^2\) have \(\pi(P) \in \R^2\) then the Riemannian metric above gives \(\inner{\cdot, \cdot}_{\pi(p)}\).

  The \emph{tangent plane} to \(S^2\) at \(P\) is
  \[
    \{x \in \R^3: x \cdot OP = 0\}.
  \]
  Then \((d\pi^{-1})_{\pi(p)}\) identifies \(\inner{\cdot, \cdot}_{\pi(p)}\) with restriction of standard inner product on \(\R^2\) to the tangent plane.
\end{eg}

Missed 2 lectures

Let
\[
  G_D = \{\text{M√∂bius transformations sending \(D\) onto \(D\)}\} \cong \PSL(2, \R).
\]

\begin{enumerate}
\item \(G_D\) acts transitively on the hyperbolic lines in \(D\) (and on paris \(\ell, P \in \ell\)).
\item The length-minimizing curves on \(D\) are segments of hyperbolic lines parameterised monotonically.
\end{enumerate}

Recall the notation \(\rho(\cdot, \cdot)\), the hyperbolic distance makes sense on \(H\) and on \(D\).

\begin{lemma}\leavevmode
  \begin{enumerate}
  \item Rotations \(z \mapsto e^{i\theta}z\), \(\theta \in \R\) are in \(G_D\).
  \item If \(a \in D\), then
    \[
      g(z) = \frac{z - a}{1 - \conj a z}
    \]
    is in \(G_D\).
  \end{enumerate}
\end{lemma}

\begin{proof}\leavevmode
  \begin{enumerate}
  \item The map is clearly linear and preserves both \(|z|\) and \(|dz|\), and thus the metric
    \[
      \frac{4|dz|^2}{(1 - |z|^2)^2}.
    \]
  \item \(g\) send \(\{|\zeta| = 1\}\) to itself: if \(|\zeta| = 1\) then
    \[
      |1 - \conj a \zeta| = |\conj \zeta (1 - \conj a \zeta)| = |\conj \zeta - \conj a| = |\zeta - a| \neq 0
    \]
    unless \(a = 0\) in which case \(g(z) = z\). Thus \(|g(\zeta) = 1\). Also \(g(a) = 0\) so \(g \in G_D\).
  \end{enumerate}
\end{proof}

This does not exhaust all elements of \(G_D\) yet. But in example sheet we will show every \(g \in G_D\) is of the form
\[
  g(z) = e^{i\theta} \frac{z - a}{1 - \conj a z}
\]
for some \(a \in D, \theta \in R\), and \(G_D \subset \Isom(D)\) is a subgroup of index \(2\).

\begin{proposition}
  If \(0 \leq r < 1\) then
  \[
    \rho(0, r) = \rho(0, e^{i\theta}r) = 2 \tanh^{-1} r.
  \]

  In general, for \(z_1, z_2 \in D\),
  \[
    \rho(z_1, z_2) = 2 \tanh^{-1} \left| \frac{z_1 - z_2}{1 - \conj z_1 z_2} \right|.
  \]
\end{proposition}

\begin{proof}
  The first equality is clear from the above lemma. Now let \(\gamma(t) = t, 0 \leq t \leq r\), a hyperbolic line segment through \(0\) and \(r\). Then from definitions the length is
  \[
    \rho(0, r) = \int_0^r \frac{2}{1 - t^2} dt = 2 \tanh^{-1} r.
  \]

  For the general case, let \(\ell\) be the hyperbolic line through \(z_1, z_2\). Apply
  \[
    g(z) = \frac{z - z_1}{1 - \conj z_1 z}
  \]
  which is an isometry by the above lemma. Then \(g(\ell)\) is a diameter. Further rotate about \(0\) to achieve \(g(z_2) = r \in \R_+\). Then
  \[
    r = |g(z_2)| = \left| \frac{z_2 - z_2}{1 - \conj z_1 z_2} \right|
  \]
  and
  \[
    \rho(z_1, z_2) = \rho(0, r) = 2 \tanh^{-1} r.
  \]
\end{proof}

\begin{remark}
  When there is a ``distinguished'' point, it is sometimes convenient to send it to \(0 \in D\) (and then use the disc model).
\end{remark}

In Euclidean geometry, we know that there is a unique line through a give point perpendicular to a given line. Similarly, we will show that

\begin{proposition}
  For all points \(P\) and hyperbolic lines \(\ell\) such that \(P \notin \ell\), there exists a unique \(\ell', P \in \ell'\) such that \(\ell'\) meet \(\ell\) orthogonally, in \(Q\) say, and
  \[
    \rho(P, Q) \leq \rho(P, \tilde Q)
  \]
  for all \(\tilde Q \in \ell\), with equality if and only if \(\tilde Q = Q\).
\end{proposition}

\begin{proof}
  Example sheet.
  %Wlog \(P = 0 \in D\).
\end{proof}

The next lemma concerns ``reflections'' in hyperbolic plane:

\begin{lemma}
  Suppose \(g\) is an isometry of \(H\) and \(g\) fixes every point in \(L^+ \subseteq H\). Then either \(g = \id_H\) or \(g(z) = - \conj z\), i.e.\ reflection in the \(y\)-axis.
\end{lemma}

\begin{proof}
  Let \(P \in H, P \notin L^+\). Then there exists a unique \(\ell \neq P, \ell' \perp L^+\). Theus \(\ell'\) must be a semi-circle. Let \(Q = \ell \cap L^+\). As \(g(Q) = Q\), \(\rho(P, Q) = \rho(g(P), Q)\). Then \(g(P) \in \ell'\) by the properties of \(\ell'\) and the uniqueness of \(\ell'\). Thus we must have either \(g(P) = P\) or \(g(P) = P'\).

  Suffices to show if \(g(P) = P\) then \(g = \id_H\) (for if \(g(P) = P'\) then compose with the isometry \(z \mapsto -\conj z\)). Let \(g(P) = R\). Wlog \(P \in H^+ = \{z \in H: \Re z > 0\}\) and consider any \(A \in H^+\). If \(g(A) = A'\) then \(\rho(A', P) = \rho(A, P)\). But
  \[
    \rho(A', P) = \rho(A', B) + \rho(B, P) = \rho(A, B) + \rho(B, P) = \rho(A, P)
  \]
  and \(B \in \ell_{AP}\), contradicting the triangle inequality.
\end{proof}

We call \(R: H \to H, z \mapsto -\conj z\) the (hyperbolic) relfection in \(L^+\). Now we can extend the definition to every hyperbolic line: for each hyperbolic line \(\ell \in H\) with \(T \in \PSL(2, \R)\) chosen such that \(T(\ell) = L^+\), we call
\[
  R_\ell = T^{-1}RT
\]
the reflection in \(\ell\). By proposition above, \(R_\ell\) is the unique non-identity isometry of \(H\) fixing \(\ell\).

\begin{ex}
  It is instructive to write out the reflections in \(\ell \subseteq D\) using an isometry \(D \to H\) and Q4 on example sheet 2.
\end{ex}

\subsection{Hyperbolic triangle}

\begin{definition}[Hyperbolic triangle]\index{hyperbolic triangle}
  A \emph{hyperbolic triangle} \(\triangle\) is the region bounded by 3 hyperbolic line segments, including the extreme cases of vertices ``at infinity'' (i.e.\ in \(\R \cup \{\infty\}\) for \(H\), in \(\{|\zeta| = 1\}\) for \(D\)) (in this case the angle is \(0\)).
\end{definition}

\begin{theorem}[Gauss-Bonnet for hyperbolic triangle]\index{Gauss-Bonnet}
  For each \(T = \triangle ABC\) with angles \(\alpha, \beta, \gamma \geq 0\), then
  \[
    \operatorname{area} T = \pi - \alpha - \beta - \gamma.
  \]
\end{theorem}

\begin{proof}
  Use the \(H\) model. Recall that for a region \(R \subseteq H\), the area is computed as
  \[
    \int\int_R \frac{dxdy}{y^2}.
  \]
  First do the case when \(\gamma = 0\), so \(C\) is ``at infinity'' (\(in\R\) or \(\infty\)). Wlog \(C = \infty\) (apply \(g \in \PSL(2, \R)\). Then \(AC\) and \(BC\) are in vertical half-lines and \(AB\) is an arc of semi-circle. Use \(z \mapsto z + a, a \in \R\) to ensure the semi-circle is centred at \(0\), \(z \mapsto bz, z > 0\) to achieve radius \(1\). Thus wlog
  \[
    AB \subseteq (\{x^2 + y^2 = 1\} \cap \{y > 0\}).
  \]
  Then
  \begin{align*}
    \operatorname{area} T
    &= \int_{\cos(\pi - \alpha)}^{\cos \beta} \int_{(1 - x^2)^{1/2}}^\infty \frac{dydx}{y^2} \\
    &= \int_{\cos (\pi - \alpha)}^{\cos \beta} \frac{1}{(1 - x^2)^{1/2}}dx \\
    &= -\arccos \Big|_{\cos (\pi - \alpha)}^{\cos \beta} \\
    &= \pi - \alpha - \beta
  \end{align*}
  as required.

  In general, using \(H\) again, we can apply \(g \in \PSL(2, \R)\) to move \(AC\) into a vertical half-line. Then as before, move \(AB\) into \(\{x^2 + y^2 = 1\}\) (and \(AC\) remains vertical). Consider \(\triangle_1 = AB\infty, \triangle_2 = CB\infty\). Apply the previous result to get
  \begin{align*}
    \operatorname{area} \triangle_1 &= \pi - \alpha - (\beta + \delta) \\
    \operatorname{area} \triangle_2 &= \pi - \delta - (\pi - \gamma)
  \end{align*}
  so
  \[
    \operatorname{area} T = \operatorname{area} \triangle_1 - \operatorname{area}_2 \pi - \alpha - \beta - \gamma.
  \]
\end{proof}

There are cosine and sine rules for hyperbolic triangles. See example sheet. Here is another observation: any two lines in \(S^2\) (great circles) always meet (in 2 points), any two lines in \(\R^2\) meet (in 1 point) if and only if not parallel.

\begin{definition}[Parallel, ultraparallel]
  Using the \(D\) model, two hyperbolic lines \(\ell_1, \ell_2 \subseteq D\) are \emph{parallel} if they meet only at \(\{|\zeta| = 1\}\).

  They are \emph{ultraparallel} if and only if they do not meet anywhere in \(\{|\zeta| \leq 1\}\).
\end{definition}

\begin{axiom}[Euclid's parallel axiom (5th axiom)]
  Given a line \(\ell\) and \(P \notin \ell\), there exists a unique line \(\ell' \ni P\) with \(\ell \cap \ell' = \emptyset\).
\end{axiom}

It fails in both \(S^2\) and hyperbolic plane --- but for very different reasons!

\subsection{THe hyperboloid model}

Consider \emph{Lorenzian} inner product \(\inner{\cdot, \cdot}\) on \(\R^3\) with matrix
\[
  \begin{pmatrix}
    1 & 0 & 0 \\
    0 & 1 & 0 \\
    0 & 0 & -1
  \end{pmatrix}
\]
with signature \(p = 2, q = 1\).

Set
\[
  %q(\V x) = \inner{\V x, \V x} = x^2 + y^2 - z^2\)
\]
and
\begin{align*}
  S &= \{\V x \in \R^3: q(\V x) = -1\} \\
  S^+ &= S \cap \{z > 0\}
\end{align*}

Define a projection from the upper sheet of the hyperboloid to the unit disc in the complex plane
\begin{align*}
  \pi: S^+ \to D \subseteq \C \\
  (x, y, z) &\mapsto \frac{x + iy}{1 + z} = u + iv
\end{align*}

Put \(r^2 = u^2 + v^2\) and by striaghforward calculation,
\begin{align*}
  \sigma = \pi^{-1}: D &\mapsto S^+ \\
  (u, v) &\mapsto \frac{1}{1 - r^2} (2u, 2v, 1 + r^2) 
\end{align*}

Now we can check the inner product on the tangent plane to \(S^+\) at \(\sigma(u, v)\) spanned by
\begin{align*}
  \sigma_u &= d\sigma(e_1) = \frac{2}{(1 - r^2)^2} (1 + u^2 - v^2, 2uv, 2u) \\
  \sigma_v &=  d\sigma(e_2) = \frac{2}{(1 - r^2)^2} (2uv, 1 + v^2 - u^2, 2v)
\end{align*}
The restriction of Lorenzian \(\inner{\cdot, \cdot}\) to the span of \(\sigma_u, \sigma_v\) assigns to each \((u, v) \in D\) a symmetric bilinear form on \(\R^2\) with
\begin{align*}
  E &= \inner{\sigma_u, \sigma_u} = \frac{4}{(1 - r^2)^2} \\
  F &= 0 \\
  G &= E
\end{align*}
which is exactly the Poincare disc model of the hyperplane.

\section{Smooth embedded surfaces}

\begin{definition}[Smooth embedded surface]\index{Smooth embedded surface}
  \(S \subseteq \R^3\) is a (parameterised) \emph{smooth embedded surface} if for all \(P \in S\), there is an open neighbourhood \(U = W \cap S\) and a map \(\sigma: V \to U\) from \(V \subseteq \R^2\) such that
  \begin{enumerate}
  \item \(\sigma\) is a homeomorphism of \(V\) into \(U\),
  \item \(\sigma(u, v)\) is \(C^\infty\),
  \item at each \(Q = \sigma(P)\), the vectors \(\frac{\p \sigma}{\p u}(P), \frac{\p \sigma}{\p v}(P)\) are linearly independent.
  \end{enumerate}
\end{definition}

\((u, v) \in V \subseteq \R^2\) are \emph{smooth coordinates} on \(U \subseteq S\). The subspace in \(\R^2\) spanned by\(\frac{\p \sigma}{\p u}(P), \frac{\p \sigma}{\p v}(P)\) is the \emph{tangent space} to \(S\) at \(\sigma(P)\). \(\sigma\) is a \emph{smooth parameterisation} of \(U \subseteq S\).

\begin{proposition}
  Suppose \(\sigma: V \to U, \tilde \sigma: \tilde V \to U\) are smooth parameterisations, then
  \[
    \varphi: \sigma^{-1} \compose \tilde \sigma: \tilde V \to V
  \]
  is a diffeomorphism.
\end{proposition}

\begin{proof}
  It suffices to consider \(\varphi\) on some neighbourhood of \(P = (u_0, v_0) \in \tilde V\). The Jacobian matrix of \(\sigma\), \(\begin{psmallmatrix} x_u & x_v \\ y_u & y_v \\ z_u & z_v \end{psmallmatrix}\) has rank 2 at each \((u, v) \in \tilde V\). Wlog
  \[
    \det
    \begin{pmatrix}
      x_u & x_v \\
      y_u & y_v
    \end{pmatrix}
    \neq 0
  \]
  at \((u_0, v_0)\). Let \(F(u, v) = \begin{psmallmatrix} x(u, x) \\ y(u, v) \end{psmallmatrix}\), then by Inverse function theorem, \(F\) maps some open \(N \subseteq \R^2, (u_0, v_0) \in N\), diffeomorphically onto an open \(N' \subseteq \R^2\).
  \[
    \begin{tikzcd}
      & \sigma(N) \ar[d, "\pi"] \\
      N \ar[ur, "\sigma"] \ar[r, "F"] & N' & \tilde N \ar[ul, "\tilde \sigma"'] \ar[l, "\tilde F"']
    \end{tikzcd}
  \]
  Here \(\sigma(N)\) is open in \(S\) as \(\sigma\) is a homeomorphism. \(\pi = F \compose \sigma^{-1}\) is bijective as \(\sigma, F\) are so. \(\tilde N = \tilde \sigma^{-1}(\sigma(N)) \subseteq \tilde V\) is open and \(\tilde F = \pi \compose \tilde \sigma\). \(\pi^{-1}: N' \to \sigma(N)\) is well-defined. Furthermore, \(\pi(x, y, z) = (x, y)\) is linear, so smooth. Now
  \[
    \varphi = \sigma^{-1} \compose \tilde \sigma = (\sigma^{-1} \compose \pi^{-1}) \compose (\pi \compose \tilde \sigma) = F^{-1} \compose \tilde F
  \]
  on \(\tilde N\) is smooth as \(F^{-1}\) and \(\tilde F\) are.

  Similarly (by symmetry of notation) \(\varphi^{-1}\) is smooth.
\end{proof}

Recall that if \(P \in V, Q \in \sigma(P)\), then the tangent space \(T_QS\) is the span of \(\sigma_u(P), \sigma_v(P)\).

\begin{corollary}
  The tangent plane \(T_QS\) is independent of \(\sigma\).
\end{corollary}

\begin{proof}
  Use the same notation as the previous propositoin. Then
  \[
    \tilde \sigma(\tilde u, \tilde v) = \sigma(\varphi_1(\tilde u, \tilde v), \varphi_2(\tilde u, \tilde v))
  \]
  where \(\varphi = (\varphi_1, \varphi_2)\) by defintion. By chain rule,
  \begin{align*}
    \tilde \sigma_{\tilde u} &= (\varphi_1)_{\tilde u} \sigma_u + (\varphi_2)_{\tilde u} \sigma_v \\
    \tilde \sigma_{\tilde v} &= (\varphi_1)_{\tilde v} \sigma_u + (\varphi_2)_{\tilde v} \sigma_v
  \end{align*}
  The Jacobian of \(\varphi\) is just the matrix composed of the coefficients in parenthesis and thus \(\varphi\) is invertible. Thus \(\sigma_u, \sigma_v\) and \(\tilde \sigma_{\tilde u}, \tilde \sigma_{\tilde v}\) have the same span.
\end{proof}

\begin{remark}
  We can compute
  \[
    \tilde \sigma_{\tilde u} \times \tilde \sigma_{\tilde v} = \det(J(\varphi)) \sigma_u \times \sigma_v.
  \]
\end{remark}

\begin{definition}[Unit normal]\index{unit normal}
  The \emph{unit normal} to \(S\) at \(Q\) is
  \[
    N = N_Q = \frac{\sigma_u \times \sigma_v}{\norm{\sigma_u \times \sigma_v}}(P).
  \]
\end{definition}

By the above remark, \(N\) is well-defined up to a sign.

\begin{definition}[Chart]\index{chart}
  \(\phi = \sigma^{-1}: U \to V\) where \(U \subseteq S, V \subseteq \R^2\) is a \emph{chart}.
\end{definition}

\begin{eg}
  For \(S^2\), the two stereographic projections, from \(\begin{psmallmatrix} 0 \\ 0 \\ \pm 1 \end{psmallmatrix}\) are charts. Their domains cover \(S^2\).
\end{eg}

\begin{definition}[First fundamental form]\index{first fundamental form}
  If \(S \subseteq \R^3\) is an embedded surface, then \(T_QS\) at each \(Q \in S\) has an induced inner product from \(\R^3\) --- the resulting family of inner products on tangent planes is called the \emph{first fundamental form} of \(S\).
\end{definition}

Given a parameterisation \(\sigma: V \to U \subseteq S, P \in V, a, b \in \R^2\), set
\[
  \inner{a, b}_P = \inner{d\sigma_P(a), d\sigma_P(b)}_{\R^3}.
\]
With respect to the standard basis \(e_1, e_2\) of \(\R^2\), RHS becomes
\begin{equation}
  \label{eqn:Riemmanian metric}
  Edu^2 + 2Fdudv + Gdv^2
  \tag{\(\ast\)}
\end{equation}
with
\begin{align*}
  E &= \inner{\sigma_u, \sigma_u} \\
  F &= \inner{\sigma_u, \sigma_v} \\
  G &= \inner{\sigma_v, \sigma_v}
\end{align*}
are \(C^\infty\) functrions of \((u, v) \in V\). Thus we have recovered our previous defintion of Riemannian metric. Thus the Riemannian metric \eqref{eqn:Riemannian metric} on \(V\) is also called the first fundamental form corresponding to a parameterisatio \(\sigma\).

(first fundamental form is abstract but invariant to parameterisation, while Riemannian metric is easier to do computations with)

\begin{definition}[Length, energy]\index{length}\index{energy}
  Given a smooth curve \(\Gamma: [a, b] \to S \subseteq \R^2\), define the \emph{length} of \(\Gamma\) to be
  \[
    \int_a^b \norm{\Gamma'(t)} dt
  \]
  and the \emph{energy} to be
  \[
    \int_a^b \norm{\Gamma'(t)}^2 dt.
  \]
\end{definition}

If \(\Gamma([a, b]) \subseteq U = \sigma(N)\) for some parameterisation \(\sigma\), then there exists a unique \(\gamma: [a, b] \to V\) such that \(\Gamma = \sigma \compose \gamma\). Thus it suffices to consider \(\gamma\), a curve ``in \(\R^2\)''. Write \(\gamma = (\gamma_1, \gamma_2)\), then
\[
  \Gamma'(t) = (d\sigma)_{\gamma(t)} (\dot \gamma_1(t)e_1 + \dot \gamma_2(t)e_2).
\]
Thus
\begin{align*}
  \Gamma'(t) &= \dot \gamma_1(t) \sigma_u|_{\gamma(t)} + \dot \gamma_2(t) \sigma_v|_{\gamma(t)} \\
  \norm{\Gamma'(t)} &= \inner{\dot \gamma, \dot \gamma}^{1/2}_{\gamma(t)} = (E \dot \gamma_1^2 + 2F \dot \gamma_1 \dot \gamma_2 + G \dot \gamma_2^2)^{1/2}.
\end{align*}
With these expressions, we can write
\begin{align*}
  \operatorname{length}(\Gamma) &= \int_a^b (E \dot \gamma_1^2 + 2F \dot \gamma_1 \dot \gamma_2 + G \dot \gamma_2^2)^{1/2} dt \\
  \operatorname{energy}(\Gamma) &= \int_a^b (E \dot \gamma_1^2 + 2F \dot \gamma_1 \dot \gamma_2 + G \dot \gamma_2^2) dt
\end{align*}

\begin{definition}[Area]\index{area}
  Given a parameterisation \(\sigma: V \to U \subseteq S \subseteq \R^3\) of \(S\) and a region \(T \pi U\), the \emph{area} of \(T\) is
  \[
    \int_{\theta(T)} \sqrt{EG - F^2} dudv
  \]
  where \(\theta = \sigma^{-1}\) is a chart, whenever RHS is defined.
\end{definition}

We state without proof a proposition:

\begin{proposition}
  The area defined as above is independent of parameterisation.
\end{proposition}
In particular, this shows that if the area does not exist in one parameterisation, then it does not exist in others as well.

\begin{remark}\leavevmode
  \begin{enumerate}
  \item In examples we encounter in this course, often \(\sigma(V) = U\) is dense in \(S\). Then area of \(S\) is just the integral over \(V\).
  \item The area and lengths on \(S\) are invariant under isometries.
  \end{enumerate}
\end{remark}

\section{Geodesics}

Let \(V \subseteq \R^2_{u, v}\) be open, \(Edu^2 + 2Fdudv + Gdv^2\) a Riemannian metric on \(V\), \(\gamma = (\gamma_1, \gamma_2): [a, b] \to V\) a smooth curve.

\begin{definition}[Geodesic]\index{geodesic}
  \(\gamma\) is a \emph{geodesic} if
  \begin{align*}
    \frac{d}{dt} (E \dot \gamma_1 + F \dot \gamma_2) &= \frac{1}{2} (E_u \dot \gamma_1^2 + 2F_u \dot \gamma_1 \dot \gamma_2 + G_u \dot \gamma_2^2) \\
    \frac{d}{dt} (F \dot \gamma_1 + G \dot \gamma_2) &= \frac{1}{2} (E_v \dot \gamma_1^2 + 2F_v \dot \gamma_1 \dot \gamma_2 + G_v \dot \gamma_2^2)
  \end{align*}
  holds for all \(t \in [a, b]\).
\end{definition}

To recoginise the importance of the definition, we need some knowledge from calculus of variantion.

\begin{definition}[Proper variation]\index{proper variation}
  Let \(\gamma(a) = p, \gamma(b) = q\). A \emph{proper variation} of \(\gamma\) is a \(C^\infty\) map \(h: [a, b] \times (-\varepsilon, \varepsilon) \to V\) such that
  \begin{align*}
    h(t, 0) &= \gamma(t) \quad \forall t \in [a, b] \\
    h(a, \tau) &= p, h(b, \tau) = q \quad \forall \tau \in (-\varepsilon, \varepsilon)
  \end{align*}
  and put \(\gamma_\tau(t) = h(t, \tau)\), \(\gamma_\tau: [a, b] \to V\) is a \(C^\infty\) curve.
\end{definition}

\begin{proposition}
  \(\gamma\) satisfies the geodesic ODE's if and only if \(\gamma\) is a stationary point for the energy for all proper variations (in the sense of Euler-Lagrange).
\end{proposition}

\begin{proof}
  Relabel \(\gamma(t) = (u(t), v(t))\). Recall that energy can be written as
  \[
    \int_a^b (E(u, v) \dot u^2 + 2F(u, v) \dot u \dot v + G(u, v) \dot v^2) dt
    = \int_a^b I(u, v, \dot u, \dot v) dt
  \]
  for some formal expression \(I\) taking 4 variables. Euler-Lagrange equations assert that \(\gamma\) is stationary if and only if
  \begin{align*}
    \frac{d}{dt} \frac{\p I}{\p \dot u} &= \frac{\p I}{\p u} \\
    \frac{d}{dt} \frac{\p I}{\p \dot v} &= \frac{\p I}{\p v}
  \end{align*}
  which in our case of \(\gamma\) is
  \begin{align*}
    2 \frac{d}{dt} (E \dot u + F \dot v) &= E_u \dot u^2 + 2F_u \dot u \dot v + G_u \dot v^2 \\ 
    2 \frac{d}{dt} (F \dot u + G \dot v) &= E_v \dot u^2 + 2F_v \dot u \dot v + G_v \dot v^2
  \end{align*}
  and the result follows.
\end{proof}

Let \(S \subseteq \R^3\) be an embedded surface and \(\sigma: V \to U\) be a parameterisation and \(\theta = \sigma^{-1}\) be a chart. Let \(\Gamma: [a, b] \to U\) be a smooth curve in \(S\). Then \(\gamma = \theta \compose \Gamma\) is a smooth curve in \(V\).

Now we can define geodesic in an equivalent but more synthetic way:

\begin{definition}[Geodesic]\index{geodesic}
  \(\Gamma\) is a \emph{geodesic curve} on \(S\) if and only if \(\gamma\) is a geodesic in \(V\). Thus \(\Gamma\) is a stationary point for the energy \(\int_a^b \norm{\Gamma'(t)}^2 dt\).
\end{definition}

Note that this is independent of the choice of chart \(\theta\).

\begin{corollary}
  If the curve \(\Gamma\) minimises the energy for curves joining \(P = \Gamma(a)\) and \(Q = \Gamma(b)\) in \(S\), then \(\Gamma\) is a geodesic.
\end{corollary}

\begin{proof}
  For all \(a \leq a_1 < b_1 \leq b\), \(\Gamma_1 = \Gamma|_{[a_1, b_1]}\) minimises energy for all curves from \(\Gamma(a_1)\) to \(\Gamma(b_1)\). If \(a_1, b_1\) are so that \(\Gamma([a_1, b_1]) \subseteq U\) for some chart \(\theta: U \to V\) then \(\Gamma_1\) is a geodesic by the previous proposition. Now just vary \(a_1, b_1\) to get a cover of \([a, b]\).
\end{proof}

So far we have characterised geodesic as energy-minimising curves. There are some valid reasons that this is helpful. To get to the more intuitive understanding of geodesic as length-minimising curve, we need a techinical lemma:

\begin{lemma}
  Let \(V \subseteq \R^2\) open and endowed with a Riemannian metric. Let \(P, Q \in V\) and consider \(C^\infty\) curves \(\gamma: [0, 1] \to V\) with \(\gamma(0) = P, \gamma(1) = Q\). Then such \(\gamma_0\) minimises energy if and only if \(\gamma_0\) minimised the length and has constant speed.
\end{lemma}

\begin{proof}
  Recall Cauchy-Schwarz for \(f, g \in C[a, b]\):
  \[
    \left( \int_a^b fg \right)^2 \leq \int_a^b f^2 \cdot \int_a^b g^2
  \]
  with equality if and only if \(g = \lambda f\) for some \(f \in \R\) or \(f = 0\).

  Put \(f = 1, g = \norm{\dot \gamma}\) (with respect to the Riemannian metric), \(a = 0, b = 1\). Then
  \[
    (\operatorname{length} \gamma)^2 \leq \operatorname{energy} \gamma
  \]
  with equality if and only if \(\norm{\dot \gamma}\) is constant. If the length is \(\ell\) then the minimal energy is \(\ell^2\), occurs precisely when \(\norm{\dot \gamma}\) is constant.
\end{proof}

This gives a necessary condition for geodesic and one naturally wonders if it is also sufficient. It turns out that it is a pretty close guess but one has to be more careful:

\begin{fact}
  \(\Gamma\) is a geodesic if and only if it locally minimises the energy and also if and only if it locally minimises energy the length and has constant speed. In this case, ``locally minimises'' means that for all \(t_0\), there exists \(\varepsilon > 0\) such that \(\Gamma|_{[t_0 - \varepsilon, t_0 + \varepsilon]}\) minimises the desired quantity. This is not a caprice of our own but comes from ODE theory.j
\end{fact}

\begin{fact}
  The geodesic ODE's imply that \(\norm{\Gamma'(t)}\) is constant, see example sheet 3.
\end{fact}

\begin{remark}
  Given that \(\begin{psmallmatrix} E & F \\ F & G \end{psmallmatrix}\) is invertible, the geodesic ODE's are equivalent to
  \[
    (\ddot u, \ddot v) = F(u, v, \dot u, \dot v)
  \]
  Following from standard theory of ODE's. For all \(P = (u_0, v_0) \in V\), for all \(\V a = (a_0, b_0) \in \R^2\), there exists a unique geodesic \(\gamma(t), |t| \varepsilon\) with \(\gamma(0) = P, \dot \gamma(0) = \V a\).
\end{remark}

\begin{eg}
  Consider the surface \(S^2\). For all \(P \in S^2\), for all tangent at \(P\), there exists a unique great circle as arcs \(< \pi\) are length-minimising. Great circles are all the geodesics on \(S^2\).
\end{eg}

Recall that
\begin{enumerate}
\item We defined the geodesic curves on a surface \(S \subseteq \R^3\) as solutions of certain ODE of 2nd order.
\item Equivalently, we can determine a geodesic \(\Gamma(t)\) uniquely by the initial condition
\begin{align*}
  \Gamma(0) &= P \in S \\
  \dot \Gamma(0) &= \V a \in T_PX
\end{align*}
where \(\Gamma: [0, T] \to S, \gamma = \sigma^{-1} \compose \Gamma\).
\item If \(\Gamma(t)\) minimises the length between its end points and \(\norm{\dot \Gamma(t)}\) is constant, then \(\Gamma(t)\) is a geodesic. This is a sufficient but not necessary condition.
\end{enumerate}

\begin{eg}\leavevmode
  \begin{enumerate}
  \item Arcs of great circles on \(S^2\) are precisely the geodesics.
  \item Similarly on a hyperbolic plane, the geodesics are precisely the hyperbolic line segments.The can also be computed directly. See example sheet.
  \end{enumerate}
\end{eg}

As solutions of geodesic ODEs depend smoothly on the initial conditions, we may use this to construct around \(P \in S\) \emph{geodesic polar coordinates}\index{geodesic polar coordinates} (i.e. a particular chart). We will do an informal construction here while the more technical details will be left to IID Differential Geometry.

\begin{proof}[Sketch of construction]
  Let \(\psi: U \to V\) be a chart. Let \(P \in U\). May assume wlog \(\psi(P) = 0 \in V\).Denote by \(\theta\) the polar angle coordinate on \(\R^2 \setminus \{0\}\). For each value of \(\theta\), there exists a unique geodesic \(\gamma^\theta: (-\varepsilon, \varepsilon) \to V\) with
  \begin{align*}
    \gamma^\theta (0) &= 0 \\
    \dot \gamma^\theta(0) &= \cos \theta e_1 + \sin \theta e_2
  \end{align*}
  Set \(\sigma(r, \theta) = \gamma^\theta(r)\). Then we can show
  \begin{enumerate}
  \item \(\sigma\) is smooth on
    \[
      W = \{(r, \theta): 0 < r < \varepsilon_0, \theta_0 < \theta < \theta_0 + 2\pi\}.
    \]
  \item For all \(\theta_0\), \(\psi^{-1} \compose \sigma: W \to S\) is a valid parameterisation. Respectivly, \(\sigma^{-1} \compose \psi\) is a valid chart on \(S\).
  \end{enumerate}
  The values \((r, \theta)\) of the chart are geodesic polar coordinates on some open \(U \subseteq S\). Note that \(P \notin U\).
\end{proof}

\begin{theorem}[Gauss' lemma]\index{Gauss' lemma}
  Geodesic circles \(\{r = r_0\} \subseteq W\) are perpendicular to their radii, i.e.\ to \(\gamma^\theta(t)\) and the induced Riemannian metric on \(W\) (i.e.\ first fundamental form with respect to \(\sigma(r, \theta)\)) is
  \[
    dr^2 + G(r, \theta) d\theta^2.
  \]
\end{theorem}

\begin{definition}[Atlas]\index{atlas}
  An \emph{atlas} on \(S\) is a collection of charts covering \(S\).
\end{definition}

For example, the family of geodesic polar charts is an atlas. There are two more examples of interesting atlases in example sheet.

\subsection{Surfaces of revolution}

In this section, \(S\) will be obtained by rotating a plane curve around a straight line \(\ell\). Wlog \(\ell\) is the \(z\)-axis in \(\R^3\) and the curve is in the \((x, z)\)-plane. Let
\begin{align*}
  \eta: (a, b) &\to \R^3 \\
  u &\mapsto (f(u), 0, g(u))
\end{align*}
where \(a\) and \(b\) may be infinite such that
\begin{enumerate}
\item \(\norm{\eta'(u)} = 1\) (see example sheet 3),
\item \(f(u) > 0\) for all \(u\),
\item \(\eta\) is a homeomorphism onto its image (this is to rule out for example, figure 8 or oscillating curve).
\end{enumerate}

Define \(S\) as the image of
\[
  \sigma(u, v) = (f(u) \cos v, f(u) \sin v, g(u)), a < u < b, 0 \leq v \leq 2\pi
\]
and for all \(\alpha \in \R\), the restriction \(\sigma^\alpha: (a, b) \times (\alpha, \alpha + 2\pi)\) is a homeomorphism onto its image.

Then
\begin{align*}
  \sigma_u &= (f' \cos v, f' \sin v, g') \\
  \sigma_v &= (-f \sin v, f \cos v, 0) \\
  \sigma_u \times \sigma_v &= (-fg' \cos v, -fg' \sin v, ff') \\
  \norm{\sigma_u \times \sigma_v} &= f^2(f'^2 + g'^2) = f^2 \neq 0
\end{align*}
Thus \(\sigma^\alpha\) is a valid parameterisation and \(S\) is a valid embedded surface.

\begin{definition}[Parallel \& meridian]\index{parallel}\index{meridian}
  Curves on \(S\) of the form \(\gamma(t) = \sigma(u_0, t)\) are \emph{parallels} and \(\gamma(t) = \sigma(t, v_0)\) are \emph{meridians}.
\end{definition}

The first fundamental form with respect to \(\sigma\) is
\begin{align*}
  E &= \norm{\sigma_u}^2 = f'^2 + g'^2 = 1 \\
  F &= \sigma_u \cdot \sigma_v = 0 \\
  G &= \norm{\sigma_v}^2 = f^2
\end{align*}
i.e.\ \(du^2 + f^2(u) dv^2\). The geodesic equations on \(S\) are
\begin{align*}
  \ddot u &= f \cdot \frac{df}{du} \cdot \dot v^2 \\
  \frac{d}{dt} (f^2 \dot v) &= 0
\end{align*}

Which of them is a geodesic?

\begin{proposition}
  Assume \(\norm{\dot \gamma}_V = 1\) where \(\gamma: I \to V \subseteq \R^2\), i.e.\ if \(\gamma = (u(t), v(t))\) then \(\dot u^2 + f^2(u)\dot v^2 = 1\). Then
  \begin{enumerate}
  \item every meridian \(\gamma\) is geodesic.
  \item a parallel \(\gamma\) is a geodesic if and only if
    \[
      \frac{df}{du}(u_0) = 0,
    \]
    i.e.\ \(u_0\) is a stationary/critical point of \(f\).
  \end{enumerate}
\end{proposition}

\begin{proof}\leavevmode
  \begin{enumerate}
  \item \(v = v_0 \) is constant so the second equation holds. As \(\dot v = 0\), \(|\dot u(t)| = 1\) so \(\ddot u = 0\) and the first equation also holds.
  \item Suppose \(u = u_0\). Then \(f^2 \dot v^2 = 1\) whence \(\dot v = \pm \frac{1}{f(u_0)} \neq 0\) is a constant so the second equation holds. Then the first equation holds if and only if \(\frac{df}{du} (u_0) = 0\).
  \end{enumerate}
\end{proof}

\section{Gaussian curvature}

Let's begin by considering a \(1\)-dimensional example. Let \(\eta: [0, \ell] \to \R^2\) be a smooth curve with \(\norm{\eta'} = 1\). Then
\[
  \eta' \cdot \eta'' = \frac{1}{2} (\eta' \cdot \eta')' = 0.
\]
Recall the \emph{curvature} \(\kappa\) at \(\eta(s)\) is determined by
\[
  \eta'' = \kappa n
\]
where \(\norm n = 1, n \cdot \eta' = 0\) is the unit normal and sign such that \(\kappa \geq 0\).

When \(f: [c, d] \to [0, \ell]\) is smooth with \(f'(t) > 0\), we may reparameterise \(\gamma(t) = \eta(f(t))\). Then \(\dot \eta = \dot f(t)\eta'(f(t))\) and \(\norm{\dot \gamma}^2 = \dot f^2\). Also \(\eta''(f(t)) = \kappa n\) where \(\kappa\) is the curvature at \(f(t)\). Then by Taylor's theorem,
\[
  \gamma(t + \Delta t) - \gamma(t) = \dot f \eta'(f(t)) \cdot \Delta t \frac{1}{2} (\ddot f \eta'(f(t)) + \dot f^2 \eta''(f(t))) \Delta t^2 + \text{ high order terms}
\]
so
\[
  (\gamma(t + \Delta t) - \gamma(t)) \cdot n = \frac{1}{2} \kappa \norm{\dot \gamma}^2 \Delta t^2 + \text{ high order terms}.
\]
On the other hand,
\[
  \norm{\gamma(t + \Delta t) - \gamma(t)}^2 = \norm{\dot \gamma}^2 \Delta t^2 + \text{ high order terms}.
\]
Comparing these two equations, \(\kappa\) is the ratio of the leading (quadratic) terms of RHS and is independent of parameterisation of the curve.

We want to generalise this to two dimension.

Let \(\sigma: V \to U\) be a parameterisation of a surface \(S \subseteq \R^3\). Apply Taylor's theorem,
\begin{align*}
  &\sigma(u + \Delta u, v + \Delta v) - \sigma(u, v) \\
  =& \sigma_u \Delta u + \Delta v \Delta v \\
  +& \frac{1}{2} (\sigma_{uu} \Delta u^2 + 2 \sigma_{uv} \Delta u \Delta v + \sigma_{vv} \Delta v^2) + \dots
\end{align*}
The ``deviation from the tangent plane'' is
\[
  (\sigma(u + \Delta u, v + \Delta v) - \sigma(u, v)) \cdot \V N + \frac{1}{2} (L \Delta u^2 + 2M \Delta u \Delta v + N \Delta v^2) + \dots
\]
where
\begin{align*}
  L &= \sigma_{uu} \cdot \V N \\
  M &= \sigma_{uv} \cdot \V N \\
  N &= \sigma_{vv} \cdot \V N
\end{align*}
Recall that
\[
  \norm{\sigma(u + \Delta u, v + \Delta v) - \sigma(u, v)}^2 = E \Delta u^2 + 2F \Delta u \Delta v + G \Delta v^2 + \dots
\]
We want to take similarly the ``quotient'' of the leading coefficients as an invariant. To do so we define

\begin{definition}[Second fundamental form]\index{second fundamental form}
  The \emph{second fundamental form} for \(S\) (on \(V\) with respect to \(\sigma\) is
  \[
    L du^2 + 2M dudv + N dv^2
  \]
  where \(L, M, N\) are smooth maps as defined above.
\end{definition}

\begin{definition}[Gaussian curvature]\index{Gaussian curvature}
  The \emph{Gaussian curvature} \(K\) of \(S\) at \(P \in S\) is
  \[
    K = \frac{LN - M^2}{EG - F^2}.
  \]
\end{definition}

If \(K > 0\), the second fundamental form is positive or negative definite. If \(K < 0\) then it is indefinite. If \(K = 0\) then it is semi-definite.

\begin{eg}[Informal]
  The unit sphere \(S^2\) has \(K > 0\). A Pringle crisp has \(K < 0\).
\end{eg}

\begin{remark}
  It can be checked, similar to the case of curves, that \(K\) is independent of the parameterisation \(\sigma\).
\end{remark}

\begin{proposition}
  Let \(\V N = \frac{\sigma_u \times \sigma_v}{\norm{\sigma_u \times \sigma_v}}\), the unit normal for a surface local patch \(\sigma\). Then at each point,
  \begin{align*}
    \V N_u &= a \sigma_u + b \sigma_v \\
    \V N_v &= c \sigma_u + d \sigma_v
  \end{align*}
  where
  \[
    -
    \begin{pmatrix}
      L & M \\
      M & N
    \end{pmatrix}
    =
    \begin{pmatrix}
      a & b \\
      c & d
    \end{pmatrix}
    \begin{pmatrix}
      E & F \\
      F & G
    \end{pmatrix}.
  \]
  In particular, \(K = ad - bc\).
\end{proposition}

\begin{proof}
  \(\norm{\V N} = 1\) so \(\V N \cdot \V N_u = \V N \cdot \V N_v = 0\) so the relations must hold for some \(a, b, c, d\). As \(\V N \cdot \sigma_u = 0\), \(\V N_u \cdot \sigma_u + \V N \cdot \sigma_{uu} = 0\) so \(\V N_n \cdot \sigma_u = -L\). Similarly \(\V N_u \cdot \sigma_v = -M = \V N_v \cdot \sigma_u\), \(\V N_v \cdot \sigma_v = -N\). Dot * with \(\sigma_u, \sigma_v\),
  \begin{align*}
    -L &= aE + bF \\
    -M &= cE + dF \\
    -M &= aF + bG \\
    -N &= cF + dG
  \end{align*}
  which is **. Taking the determinants, obtain \(K = ad - bc\).
\end{proof}

\begin{theorem}
  Suppose for a parameterisation \(\sigma: V \to U\) the first fundamental form is \(du^2 + G(u, v) dv^2\). Then
  \[
    K = -\frac{(\sqrt G)_{uu}}{\sqrt G}.
  \]
\end{theorem}
We notice that this formula for Gaussian curvature depends on the first fundamental form only. In fact, the general case, found in example sheet 3, is not much more difficult.

\begin{proof}
  Set \(e = \sigma_u, f = \frac{\sigma_v}{\sqrt G}, \V N\) is an orthonormal basis of \(\R^3\) dependent on \((u, v)\). Take dot products, \(e \cdot e = 1\) so \(e \cdot e_u = 0 = e \cdot e_v\). Thus we may write
  \begin{align*}
    dagger
    e_u &= \alpha f + \lambda_1 \V N \\
    e_v &= \beta f + \lambda_2 \V N \\
    f_u &= - \tilde \alpha e + \mu_1 \V N \\
    f_v &= - \tilde \beta e + \mu_2 \V N
  \end{align*}
  Since \(e \cdot f = 0\), we have
  \begin{align*}
    e_u \cdot f + e \cdot f_u &= 0 \\
    e_v \cdot f + e \cdot f_v &= 0
  \end{align*}
  so \(\alpha = \tilde \alpha, \beta = \tilde \beta\). But
  \[
    \alpha = e_u \cdot f = \sigma_{uu} \cdot \frac{\sigma_v}{\sqrt G} = [\underbrace{(\sigma_u \sigma_v)}_{= F = 0}_u - \frac{1}{2}(\sigma_u\sigma_u)_v = 0.
  \]
  Similarly
  \[
    \beta = e_v \cdot f = \sigma_{uv} \cdot \frac{\sigma_v}{\sqrt G} = \frac{G_u}{\sqrt G} = (\sqrt G)_u.
  \]
  Using dagger again,
  \begin{align*}
    & \lambda_1 \mu_2 - \lambda_2 \mu_2 \\
    &= e_u \cdot f_v - e_v \cdot f_u \\
    &= (e \cdot f_v)_u - \underbrace{(e \cdot f_u)}_{= -\tilde \alpha = 0}_v \\
    &= -\beta_u \\
    &= - (\sqrt G)_{uu}
  \end{align*}
  Now from * in the previous proposition,
  \begin{align*}
    & \V N_u \times \V N_v \\
    &= (a \sigma_u + b \sigma_v) \times (c \sigma_u + d \sigma_v) \\
    &= (ad - bc) \sigma_u \times \sigma_v \\
    &= K \sigma_u \times \sigma_v \\
    &= K \sqrt G e \times f \\
    &= K \sqrt G \V N
  \end{align*}
  so
  \begin{align*}
    K \sqrt G
    &= (\V N_u \times \V N_v) \cdot \V N \\
    &= (\V N_n \times \V N_v) \cdot (e \times f) \\
    &= (\V N \cdot e_u) (\V N \cdot f_v) - (\V N \cdot f_u) (\V \cdot e_v) \\
    &= \lambda_1 \mu_2 - \lambda_2 \mu_1 \\
    &= - (\sqrt G)_{uu}
  \end{align*}
\end{proof}









\printindex

\iffalse
Other courses that might be useful: topology, part of analysis II (differentiability in R^n and inverse function theorem)

Leads to: IID Differential Geometry

Reading List

P.\ Wilson, Curverd Spaces, CUP 2008
From classical geometries to elementary differential geometry
\fi


\end{document}
